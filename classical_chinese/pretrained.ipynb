{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is the notebook for the pretrained model from huggingface.\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pre-trained model that can translate from classical Chinese to modern Chinese.\"\"\"\n",
    "from transformers import (\n",
    "EncoderDecoderModel,\n",
    "AutoTokenizer\n",
    ")\n",
    "PRETRAINED = \"raynardj/wenyanwen-ancient-translate-to-modern\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED)\n",
    "model = EncoderDecoderModel.from_pretrained(PRETRAINED)\n",
    "def inference(text):\n",
    "  tk_kwargs = dict(\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    padding=\"max_length\",\n",
    "    return_tensors='pt')\n",
    " \n",
    "  inputs = tokenizer([text,],**tk_kwargs)\n",
    "  with torch.no_grad():\n",
    "      return tokenizer.batch_decode(\n",
    "          model.generate(\n",
    "          inputs.input_ids,\n",
    "          attention_mask=inputs.attention_mask,\n",
    "          num_beams=3,\n",
    "          max_length=256,\n",
    "          bos_token_id=101,\n",
    "          eos_token_id=tokenizer.sep_token_id,\n",
    "          pad_token_id=tokenizer.pad_token_id,\n",
    "      ), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：臣本布衣，躬耕于南阳，苟全性命于乱世，不求闻达于诸侯。先帝不以臣卑鄙，猥自枉屈，三顾臣于草庐之中，咨臣以当世之事，由是感激，遂许先帝以驱驰。后值倾覆，受任于败军之际，奉命于危难之间，尔来二十有一年矣。\n",
      "输出：\n",
      "我本是平民，在南阳亲自耕种，苟且保全性命于乱世，不求闻名于诸侯，先帝不因为我卑鄙，枉自屈服，三次在草庐中询问我，向我咨询当世的事情，因此感激，于是答应先帝驰骋，后来遇到国家覆灭，受任于败军之际，奉命于危难之际，从此以来已经二十一年了。"
     ]
    }
   ],
   "source": [
    "\"\"\"Use it!\"\"\"\n",
    "inputs = input(\"请输入想要翻译的句子\")\n",
    "print(\"输入：\", end=\"\")\n",
    "print(inputs)\n",
    "print(\"输出：\")\n",
    "lst = inference(inputs)\n",
    "# print(lst)\n",
    "for i in lst[0]:\n",
    "    if i != ' ':\n",
    "        print(i, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pre-trained model that can punctuate classical Chinese sentences.\"\"\"\n",
    "from transformers import AutoTokenizer, BertForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "TAG = \"raynardj/classical-chinese-punctuation-guwen-biaodian\"\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(TAG)\n",
    "tokenizer = AutoTokenizer.from_pretrained(TAG)\n",
    "ner = pipeline(\"ner\", model, tokenizer=tokenizer)\n",
    "\n",
    "def mark_sentence(x: str):\n",
    "    outputs = ner(x)\n",
    "    x_list = list(x)\n",
    "    for i, output in enumerate(outputs):\n",
    "        x_list.insert(output['end']+i, output['entity'])\n",
    "    return \"\".join(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：永和九年岁在癸丑暮春之初会于会稽山阴之兰亭\n",
      "输出：\n",
      "永和九年，岁在癸丑暮春之初，会于会稽山阴之兰亭。\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Use it!\"\"\"\n",
    "inputs = input(\"请输入想要断句的句子\")\n",
    "print(\"输入：\", end='')\n",
    "print(inputs)\n",
    "print(\"输出：\")\n",
    "print(mark_sentence(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3dff56455c56bca7\n",
      "Reusing dataset text (/Users/kuangyuxuan/.cache/huggingface/datasets/text/default-3dff56455c56bca7/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.02it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Now let's fine tune the models...\"\"\"\n",
    "# dataset\n",
    "from datasets import load_dataset\n",
    "my_data = load_dataset('text', data_files={'source':'dataset/lunyu_classical.txt', 'target':'dataset/lunyu_modern.txt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    source: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 616\n",
       "    })\n",
       "    target: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 616\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '子曰：“为政以德，譬如北辰，居其所而众星共之。”'} {'text': '孔子说：“用道德来统治国家的人，就会像北极星一样处在一定的位置，所有的星辰都会环绕在它的周围。”'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(my_data['source'][0], my_data['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '子曰：“为政以德，譬如北辰，居其所而众星共之。”'} {'text': '孔子说：“用道德来统治国家的人，就会像北极星一样处在一定的位置，所有的星辰都会环绕在它的周围。”'}\n"
     ]
    }
   ],
   "source": [
    "print(my_data['source'][0], my_data['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '子曰：“野哉由也！君子于其所不知，盖阙如也。名不正，则言不顺；言不顺，则事不成；事不成，则礼乐不兴；礼乐不兴，则刑罚不中；刑罚不中，则民无所措手足。故君子名之必可言也，言之必可行也。君子于其言，无所苟而已矣。”'} {'text': '孔子说：“仲由，真是鲁莽啊。君子对于自己所不知道的，总是采取存疑的态度。名分不正，说起话来就不顺当合理，说话不顺当合理，事情就办不成。事情办不成，礼乐也就不能兴盛。礼乐不能兴盛，刑罚的执行就不会得当。刑罚不得当，百姓就不知怎么办好。所以，君子一定要定下一个名分，必须能够说得明白，说出来一定能够行得通。君子对于自己的言行，是从来不马虎对待的。”'}\n"
     ]
    }
   ],
   "source": [
    "my_data = my_data.shuffle(seed=114514)\n",
    "print(my_data['source'][0], my_data['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    source: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 616\n",
       "    })\n",
       "    target: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 616\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/kuangyuxuan/.cache/huggingface/datasets/text/default-3dff56455c56bca7/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-9cad5e824cb70ae8.arrow\n",
      "Loading cached processed dataset at /Users/kuangyuxuan/.cache/huggingface/datasets/text/default-3dff56455c56bca7/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-de92afc05f887770.arrow\n"
     ]
    }
   ],
   "source": [
    "my_data.save_to_disk('dataset/lunyu_classical_modern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "reloaded_encoded_dataset = load_from_disk(\"dataset/lunyu_classical_modern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_encoded_dataset['source']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = 'classical'\n",
    "target_lang = 'modern'\n",
    "\n",
    "def preprocess(examples):\n",
    "    inputs = examples['source']['text']\n",
    "    targets = examples['target']['text']\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = reloaded_encoded_dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/dataload.py:95: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.feature = np.array(self.feature)\n",
      "/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/dataload.py:96: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.label = np.array(self.label)\n"
     ]
    }
   ],
   "source": [
    "from dataload import *\n",
    "data_path = 'dataset/lunyu.json'\n",
    "c2m_data = MyDataset_unembed(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mixed precision training with AMP or APEX (`--fp16` or `--bf16`) and half precision evaluation (`--fp16_full_eval` or `--bf16_full_eval`) can only be used on CUDA devices.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb Cell 19'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=0'>1</a>\u001b[0m training_args \u001b[39m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=1'>2</a>\u001b[0m     output_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./results\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=2'>3</a>\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=3'>4</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m2e-5\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=4'>5</a>\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=5'>6</a>\u001b[0m     per_device_eval_batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=6'>7</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=7'>8</a>\u001b[0m     save_total_limit\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=8'>9</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=9'>10</a>\u001b[0m     fp16\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=10'>11</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=12'>13</a>\u001b[0m trainer \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=13'>14</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=14'>15</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=17'>18</a>\u001b[0m     data_collator\u001b[39m=\u001b[39mdata_collator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=18'>19</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/pretrained.ipynb#ch0000017?line=20'>21</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m<string>:93\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_on_each_node, no_cuda, seed, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, xpu_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, deepspeed, label_smoothing_factor, optim, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, gradient_checkpointing, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, sortish_sampler, predict_with_generate, generation_max_length, generation_num_beams)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py:855\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=846'>847</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim \u001b[39m=\u001b[39m OptimizerNames\u001b[39m.\u001b[39mADAFACTOR\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=848'>849</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=849'>850</a>\u001b[0m     is_torch_available()\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=850'>851</a>\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=851'>852</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mGPU_NUM_DEVICES\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=852'>853</a>\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16_full_eval \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16_full_eval)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=853'>854</a>\u001b[0m ):\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=854'>855</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=855'>856</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixed precision training with AMP or APEX (`--fp16` or `--bf16`) and half precision evaluation (`--fp16_full_eval` or `--bf16_full_eval`) can only be used on CUDA devices.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=856'>857</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=858'>859</a>\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf32 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/training_args.py?line=859'>860</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf32:\n",
      "\u001b[0;31mValueError\u001b[0m: Mixed precision training with AMP or APEX (`--fp16` or `--bf16`) and half precision evaluation (`--fp16_full_eval` or `--bf16_full_eval`) can only be used on CUDA devices."
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=c2m_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Gare--Classical_Chinese_to_Modern_Chinese-14a62e76f735aeb5\n",
      "Reusing dataset text (/Users/kuangyuxuan/.cache/huggingface/datasets/text/Gare--Classical_Chinese_to_Modern_Chinese-14a62e76f735aeb5/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Gare/Classical_Chinese_to_Modern_Chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 6\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': '古文：中行迫欲得植秉铨，而骋其私。'},\n",
       " {'text': '现代文：吴中行想让李植掌管官吏的选拔，是想任意任用他的人。'},\n",
       " {'text': '古文：乃已。'},\n",
       " {'text': '现代文：于是停止。'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0], dataset['train'][1], dataset['train'][2], dataset['train'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/dataload.py:95: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.feature = np.array(self.feature)\n",
      "/Users/kuangyuxuan/Desktop/22Spring/Intro2AI/NLP_/Intro2AI_NLP/classical_chinese/dataload.py:96: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.label = np.array(self.label)\n"
     ]
    }
   ],
   "source": [
    "from dataload import *\n",
    "data_path = 'dataset/lunyu.json'\n",
    "c2m_data = MyDataset_unembed(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataload.MyDataset_unembed at 0x7fede03edd60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2m_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataload.MyDataset_unembed"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(c2m_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2m_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask']], dtype='<U14'),\n",
       " array([['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        ['input_ids', 'token_type_ids', 'attention_mask']], dtype='<U14'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2m_data[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
